{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "## Description\n",
    "\n",
    "### Data\n",
    "[Reuters-21578 Text Categorization Collection Data Set](https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection) - about 2 million instances, 28MB in size\n",
    "\n",
    "\n",
    "News: 21 SGML files\n",
    "We only deal with news contents inside <body> </body> tags\n",
    "The other files will not be needed in this homework\n",
    "\n",
    "### Format\n",
    "One text file consisting of lines of records.\n",
    "\n",
    "Each record contains 9 attributes separated by semicolons: \n",
    "\n",
    "\n",
    "Reuters-21578, Distribution 1.0 includes five files (all-exchanges-strings.lc.txt, all-orgs-strings.lc.txt, all-people-strings.lc.txt, all-places-strings.lc.txt, and all-topics-strings.lc.txt) which list the names of *all* legal categories in each set. A sixth file, cat-descriptions_120396.txt gives some additional information on the category sets.\n",
    "\n",
    "\n",
    "### Task\n",
    "4 subtasks:\n",
    "+ (30pt) Given the Reuters-21578 dataset, please calculate all k-shingles and output the set representation of the text dataset as a matrix.\n",
    "+ (30pt) Given the set representation, compute the minhash signatures of all documents using MapReduce.\n",
    "+ (40pt) Implement the LSH algorithm by MapReduce and output the resulting candidate pairs of similar documents. \n",
    "+ (Bonus) Implement K-nearest neighbor (KNN) search using LSH and compare its performance with linear search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Format\n",
    "\n",
    "1. Set representation:\n",
    "A MxN matrix: with rows as shingles and columns as documents (N=21,578) \n",
    "2. minhash signatures:\n",
    "The HxN signature matrix: with H as the number of hash functions, N=21,578\n",
    "3. candidate pairs:\n",
    "For each document i, there should be a list of those documents j>i with which i needs to be compared\n",
    "4. comparison of KNN search an linear search\n",
    "\n",
    "\n",
    "## Implementation Notes\n",
    "\n",
    "Note the differences in rows and columns for the input data and the output matrices\n",
    "* Input: rows as documents\n",
    "* Output: columns as documents\n",
    "\n",
    "Your program should be able to accept some parameters:\n",
    "* k in k-shingles\n",
    "* Number of hash functions H\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Entity:       org.apache.spark.sql.SparkSession@f26a3fa\n",
      "Spark version:      2.2.0\n",
      "Spark master:       local[*]\n",
      "Running 'locally'?: true\n"
     ]
    }
   ],
   "source": [
    "// Pre-Configured Spark Context in sc\n",
    "\n",
    "println(\"Spark Entity:       \" + spark)\n",
    "println(\"Spark version:      \" + spark.version)\n",
    "println(\"Spark master:       \" + spark.sparkContext.master)\n",
    "println(\"Running 'locally'?: \" + spark.sparkContext.isLocal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE lewis SYSTEM \"lewis.dtd\">\n",
      "<REUTERS TOPICS=\"NO\" LEWISSPLIT=\"TEST\" CGISPLIT=\"TRAINING-SET\" OLDID=\"20436\" NEWID=\"21001\">\n",
      "<DATE>19-OCT-1987 15:37:46.03</DATE>\n",
      "<TOPICS></TOPICS>\n",
      "<PLACES></PLACES>\n",
      "<PEOPLE></PEOPLE>\n",
      "<ORGS></ORGS>\n",
      "<EXCHANGES></EXCHANGES>\n",
      "<COMPANIES></COMPANIES>\n",
      "<UNKNOWN> \n",
      "&#5;&#5;&#5;F \n",
      "&#22;&#22;&#1;f2882&#31;reute\n",
      "f f BC-CITYFED-FINANCI   10-19 0013</UNKNOWN>\n",
      "<TEXT TYPE=\"BRIEF\">&#2;\n",
      "******<TITLE>CITYFED FINANCIAL CORP SAYS IT CUT QTRLY DIVIDEND TO ONE CENT FROM 10 CTS/SHR\n",
      "</TITLE>Blah blah blah.\n",
      "&#3;\n",
      "\n",
      "</TEXT>\n",
      "</REUTERS>\n",
      "<REUTERS TOPICS=\"YES\" LEWISSPLIT=\"TEST\" CGISPLIT=\"TRAINING-SET\" OLDID=\"20435\" NEWID=\"21002\">\n",
      "<DATE>19-OCT-1987 15:35:53.55</DATE>\n",
      "<TOPICS><D>crude</D><D>ship</D></TOPICS>\n",
      "<PLACES><D>bahrain</D><D>iran</D><D>usa</D></PLACES>\n",
      "<PEOPLE></PEOPLE>\n",
      "<ORGS></ORGS>\n",
      "<EXCHANGES></EXCHANGES>\n",
      "<COMPANIES></COMPANIES>\n",
      "<UNKNOWN> \n",
      "&#5;&#5;&#5;Y \n",
      "&#22;&#22;&#1;f2873&#31;reute\n",
      "r f AM-GULF-PLATFORM   10-19 0101</UNKNOWN>\n",
      "<TEXT>&#2;\n",
      "<TITLE>HUGE OIL PLATFORMS DOT GULF LIKE BEACONS</TITLE>\n",
      "<AUTHOR>    By ASHRAF FOUAD</AUTHOR>\n",
      "<DATELINE>    BAHRAIN, Oct 19 - </DATELINE><BODY>Huge oil platforms dot the Gulf like\n",
      "beacons -- usually lit up like Christmas trees at night.\n",
      "    One of them, sitting astride the Rostam offshore oilfield,\n",
      "was all but blown out of the water by U.S. Warships on Monday.\n",
      "    The Iranian platform, an unsightly mass of steel and\n",
      "concrete, was a three-tier structure rising 200 feet (60\n",
      "metres) above the warm waters of the Gulf until four U.S.\n",
      "Destroyers pumped some 1,000 shells into it.\n",
      "    The U.S. Defense Department said just 10 pct of one section\n",
      "of the structure remained.\n",
      "    U.S. helicopters destroyed three Iranian gunboats after an\n",
      "American helicopter came under fire earlier this month and U.S.\n",
      "forces attacked, seized, and sank an Iranian ship they said had\n",
      "been caught laying mines.\n",
      "    But Iran was not deterred, according to U.S. defense\n",
      "officials, who said Iranian forces used Chinese-made Silkworm\n",
      "missiles to hit a U.S.-owned Liberian-flagged ship on Thursday\n",
      "and the Sea Isle City on Friday.\n",
      "    Both ships were hit in the territorial waters of Kuwait, a\n",
      "key backer of Iraq in its war with Iran.\n",
      "    Henry Schuler, a former U.S. diplomat in the Middle East\n",
      "now with CSIS said Washington had agreed to escort Kuwaiti\n",
      "tankers in order to deter Iranian attacks on shipping.\n",
      "    But he said the deterrence policy had failed and the level\n",
      "of violence and threats to shipping had increased as a result\n",
      "of U.S. intervention and Iran's response.\n",
      "    The attack on the oil platform was the latest example of a\n",
      "U.S. \"tit-for-tat\" policy that gave Iran the initiative, said\n",
      "Harlan Ullman, an ex-career naval officer now with CSIS.\n",
      "    He said with this appraoch America would suffer \"the death\n",
      "of one thousand cuts.\"\n",
      "    But for the United States to grab the initiative\n",
      "militarily, it must take warlike steps such as mining Iran's\n",
      "harbors or blockading the mouth of the Gulf through which its\n",
      "shipping must pass, Schuler said.\n",
      "    He was among those advocating mining as a means of bringing\n",
      "Iran to the neogtiating table. If vital supplies were cut off,\n",
      "Tehran could not continue the war with Iraq.\n",
      "    Ullman said Washington should join Moscow in a diplomatic\n",
      "initiative to end the war and the superpowers should impose an\n",
      "arms embargo against Tehran if it refused to negotiate.\n",
      "    He said the United States should also threaten to mine and\n",
      "blockade Iran if it continued fighting and must press Iraq to\n",
      "acknowledge responsibility for starting the war as part of a\n",
      "settlement.\n",
      "    Iranian and Western diplomats say Iraq started the war by\n",
      "invading Iran's territory in 1980. Iraq blames Iran for the\n",
      "outbreak of hostilities, which have entailed World War I-style\n",
      "infantry attacks resulting in horrific casualties.\n",
      "    Each side has attacked the others' shipping.\n",
      " Reuter\n",
      "&#3;</BODY></TEXT>\n",
      "</REUTERS>\n",
      "<REUTERS TOPICS=\"YES\" LEWISSPLIT=\"TEST\" CGISPLIT=\"TRAINING-SET\" OLDID=\"20434\" NEWID=\"21003\">\n",
      "<DATE>19-OCT-1987 15:34:40.05</DATE>\n",
      "<TOPICS><D>acq</D></TOPICS>\n",
      "<PLACES></PLACES>\n",
      "<PEOPLE></PEOPLE>\n",
      "<ORGS></ORGS>\n",
      "<EXCHANGES></EXCHANGES>\n",
      "<COMPANIES></COMPANIES>\n",
      "<UNKNOWN> \n",
      "&#5;&#5;&#5;F \n",
      "&#22;&#22;&#1;f2863&#31;reute\n",
      "b f BC-CCR-VIDEO-SAYS   10-19 0015</UNKNOWN>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data = ./data/reut2-021.sgm MapPartitionsRDD[3] at textFile at <console>:29\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "./data/reut2-021.sgm MapPartitionsRDD[3] at textFile at <console>:29"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = spark.sparkContext.textFile(\"./data/reut2-021.sgm\")\n",
    "data.take(100).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:48: error: value toSeq is not a member of scala.util.matching.Regex.Match\n",
       "        val matchList = m.toSeq\n",
       "                          ^\n",
       "<console>:51: error: scala.util.matching.Regex.Match does not take parameters\n",
       "        list += (m(1),m(2))\n",
       "                  ^\n",
       "<console>:51: error: scala.util.matching.Regex.Match does not take parameters\n",
       "        list += (m(1),m(2))\n",
       "                       ^\n",
       "<console>:47: error: type mismatch;\n",
       " found   : Unit\n",
       " required: TraversableOnce[?]\n",
       "    for(m <- regex.findAllIn(string).matchData){\n",
       "          ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.ListBuffer\n",
    "val data2 = spark.sparkContext.wholeTextFiles(\"./data/reut2-021.sgm\")\n",
    "\n",
    "var regex = \"\"\"(?Us)<REUTERS.*NEWID=\"(\\d*)\".*>.*<TEXT.*>(.*)<\\/TEXT>.*<\\/REUTERS>\"\"\".r\n",
    "var newsParse = data2.flatMap{\n",
    "    case (path, string)  =>\n",
    "    var list =  ListBuffer[Any]()\n",
    "    var itr =  regex.findAllIn(string)\n",
    "    for(m <- regex.findAllIn(string).matchData){\n",
    "        val matchList = m.toSeq\n",
    "//         val matchedData = e\n",
    "//         list += matchedData\n",
    "        list += (m(1),m(2))\n",
    "    }\n",
    "//     for(m <- regex.findAllIn(string).matchData;\n",
    "//       e <- m.subgroups)\n",
    "//       if(e!=null) list+=e\n",
    "//     list.toSeq\n",
    "}\n",
    "// newsParse.take(5).foreach(println)\n",
    "println(newsParse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Find Min, Max and Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(Global Active Power -> 2049280, Global Reactive Power -> 2049280, Global Intensity -> 2049280, Voltage -> 2049280)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val count = flattenData.map{case (k,v) => (k,1)}.reduceByKey((i, j) => i+j).collectAsMap()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(Global Active Power -> 11.122, Global Reactive Power -> 1.39, Global Intensity -> 48.4, Voltage -> 254.15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val max = flattenData.reduceByKey{(i, j) => if (i>j) i else j}.collectAsMap()\n",
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(Global Active Power -> 0.076, Global Reactive Power -> 0.0, Global Intensity -> 0.2, Voltage -> 223.2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val min = flattenData.reduceByKey{(i, j) => if (i<j) i else j}.collectAsMap()\n",
    "min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Mean & Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(Global Active Power -> 1.0916150365005446, Global Reactive Power -> 0.12371447630388221, Global Intensity -> 4.627759310588324, Voltage -> 240.8398579745135)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val average = flattenData.reduceByKey((i, j) => i+j).map{case (i, j) => (i,j/2049280)}.collectAsMap()\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(Global Active Power -> 1.0572939031266613, Global Reactive Power -> 0.11272195204783488, Global Intensity -> 4.444395175407247, Voltage -> 3.239985888491343)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val std = flattenData.\n",
    "    map{case (k,v) => (k, scala.math.pow(v-average(k),2))}.\n",
    "    reduceByKey((i,j) => i+j).\n",
    "    map{case (k,v) => (k, math.sqrt(v/count(k)))}.collectAsMap()\n",
    "std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((Global Active Power,0.3747963063552418), (Global Reactive Power,0.30071942446043165), (Voltage,0.376090468497577), (Global Intensity,0.37759336099585067), (Global Active Power,0.4783632084012313), (Global Reactive Power,0.31366906474820144), (Voltage,0.33699515347334413), (Global Intensity,0.47302904564315357), (Global Active Power,0.4796306355241717), (Global Reactive Power,0.35827338129496406))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val norm = flattenData.take(10).map{case (k,v) => (k, (v-min(k))/(max(k)-min(k)))}\n",
    "norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Global Active Power:\n",
      "        Number of Meaningful Data - 2049280\n",
      "        Maximum Value - 11.122\n",
      "        Minimum Value - 0.076\n",
      "        Mean - 1.0916150365005446\n",
      "        Standard Deviation - 1.0572939031266613\n",
      "\n",
      "For Global Reactive Power:\n",
      "        Number of Meaningful Data - 2049280\n",
      "        Maximum Value - 1.39\n",
      "        Minimum Value - 0.0\n",
      "        Mean - 0.12371447630388221\n",
      "        Standard Deviation - 0.11272195204783488\n",
      "\n",
      "For Voltage:\n",
      "        Number of Meaningful Data - 2049280\n",
      "        Maximum Value - 254.15\n",
      "        Minimum Value - 223.2\n",
      "        Mean - 240.8398579745135\n",
      "        Standard Deviation - 3.239985888491343\n",
      "\n",
      "For Global Intensity:\n",
      "        Number of Meaningful Data - 2049280\n",
      "        Maximum Value - 48.4\n",
      "        Minimum Value - 0.2\n",
      "        Mean - 4.627759310588324\n",
      "        Standard Deviation - 4.444395175407247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "object MyFunctions {\n",
    "    def myprint(s: String): Unit = {\n",
    "        println(\"For \"+s+\":\")\n",
    "        println(\"        Number of Meaningful Data - \" + count(s))\n",
    "        println(\"        Maximum Value - \" + max(s))\n",
    "        println(\"        Minimum Value - \" + min(s))\n",
    "        println(\"        Mean - \" + average(s))\n",
    "        println(\"        Standard Deviation - \" + std(s) + \"\\n\")\n",
    "    }    \n",
    "}\n",
    "\n",
    "MyFunctions.myprint(\"Global Active Power\")\n",
    "MyFunctions.myprint(\"Global Reactive Power\")\n",
    "MyFunctions.myprint(\"Voltage\")\n",
    "MyFunctions.myprint(\"Global Intensity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "// For implicit conversions from RDDs to DataFrames\n",
    "val spark2 = spark\n",
    "import spark2.implicits._\n",
    "\n",
    "object Norm {\n",
    "    def AP(s: String): Double = {\n",
    "        process(s, \"Global Active Power\")\n",
    "    } \n",
    "    \n",
    "    def RP(s: String): Double = {\n",
    "        process(s, \"Global Reactive Power\")\n",
    "    } \n",
    "    \n",
    "    def V(s: String): Double = {\n",
    "        process(s, \"Voltage\")\n",
    "    } \n",
    "    \n",
    "    def I(s: String): Double = {\n",
    "        process(s, \"Global Intensity\")\n",
    "    } \n",
    "    \n",
    "    def process(s: String, k: String): Double = {\n",
    "        var retVal = 0.0\n",
    "        if(s == \"?\"){\n",
    "            retVal = Double.NaN\n",
    "        }else{\n",
    "            retVal = (s.toDouble-min(k))/(max(k)-min(k))\n",
    "        }\n",
    "        retVal\n",
    "    }\n",
    "}\n",
    "\n",
    "val dataDF = rows.\n",
    "                map(_.split(\";\")).\n",
    "                map(att => (att(0), att(1), Norm.AP(att(2)), Norm.RP(att(3)), Norm.V(att(4)), Norm.I(att(5)) )).\n",
    "                toDF(\"Date\", \"Time\", \"Active_Power\", \"Reactive_Power\",\"Voltage\",\"Intensity\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF.write.csv(\"./data/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+-------------------+-------------------+--------------------+\n",
      "|     Date|    Time|        Active_Power|     Reactive_Power|            Voltage|           Intensity|\n",
      "+---------+--------+--------------------+-------------------+-------------------+--------------------+\n",
      "|28/4/2007|00:00:00| 0.11696541734564549| 0.0618705035971223|0.31825525040387775| 0.11618257261410789|\n",
      "|28/4/2007|00:01:00|  0.1171464783632084| 0.0618705035971223|0.32374798061389354| 0.11618257261410789|\n",
      "|28/4/2007|00:02:00| 0.11732753938077133|0.06330935251798561| 0.3350565428109854| 0.11618257261410789|\n",
      "|28/4/2007|00:03:00|  0.1171464783632084| 0.0618705035971223| 0.3295638126009697| 0.11618257261410789|\n",
      "|28/4/2007|00:04:00| 0.11696541734564549| 0.0618705035971223| 0.3247172859450729| 0.11618257261410789|\n",
      "|28/4/2007|00:05:00| 0.11696541734564549| 0.0618705035971223|0.32213247172859427| 0.11618257261410789|\n",
      "|28/4/2007|00:06:00|  0.1171464783632084| 0.0618705035971223|0.32859450726979034| 0.11618257261410789|\n",
      "|28/4/2007|00:07:00| 0.11642223429295674|  0.060431654676259| 0.3021001615508891| 0.11618257261410789|\n",
      "|28/4/2007|00:08:00| 0.11642223429295674|  0.060431654676259| 0.2982229402261717| 0.11618257261410789|\n",
      "|28/4/2007|00:09:00| 0.11678435632808257| 0.0618705035971223| 0.3185783521809373| 0.11618257261410789|\n",
      "|28/4/2007|00:10:00| 0.11696541734564549| 0.0618705035971223|0.32084006462035547| 0.11618257261410789|\n",
      "|28/4/2007|00:11:00|  0.1171464783632084| 0.0618705035971223|0.33085621970920853| 0.11618257261410789|\n",
      "|28/4/2007|00:12:00|   0.126923773311606|0.14244604316546763| 0.3353796445880458|  0.1286307053941909|\n",
      "|28/4/2007|00:13:00| 0.11950027159152633| 0.1510791366906475| 0.3421647819063004| 0.12033195020746888|\n",
      "|28/4/2007|00:14:00|0.037298569617961255|0.15683453237410072| 0.3744749596122778|0.041493775933609964|\n",
      "|28/4/2007|00:15:00| 0.03766069165308709|0.13093525179856116|0.40516962843295684|0.041493775933609964|\n",
      "|28/4/2007|00:16:00|0.038203874705775846|0.14676258992805755| 0.4029079159935377|0.041493775933609964|\n",
      "|28/4/2007|00:17:00| 0.03802281368821293|0.14676258992805755|0.40161550888529884|0.041493775933609964|\n",
      "|28/4/2007|00:18:00| 0.03784175267065001|0.14676258992805755| 0.4009693053311799|0.041493775933609964|\n",
      "|28/4/2007|00:19:00|0.037479630635524175|0.14532374100719425| 0.3819063004846531|0.041493775933609964|\n",
      "|28/4/2007|00:20:00| 0.03766069165308709|0.14964028776978416| 0.4213247172859455|0.041493775933609964|\n",
      "|28/4/2007|00:21:00|                 NaN|                NaN|                NaN|                 NaN|\n",
      "|28/4/2007|00:22:00|                 NaN|                NaN|                NaN|                 NaN|\n",
      "|28/4/2007|00:23:00|                 NaN|                NaN|                NaN|                 NaN|\n",
      "|28/4/2007|00:24:00|                 NaN|                NaN|                NaN|                 NaN|\n",
      "+---------+--------+--------------------+-------------------+-------------------+--------------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.createOrReplaceTempView(\"records\")\n",
    "spark.sql(\"SELECT * FROM records WHERE date = '28/4/2007'\").show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "103820004 Michael Fu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

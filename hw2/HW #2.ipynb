{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "## Description\n",
    "\n",
    "### Data\n",
    "[News Popularity in Multiple Social Media Platforms Data Set](https://archive.ics.uci.edu/ml/datasets/News+Popularity+in+Multiple+Social+Media+Platforms) - 13 CSV files, 155MB in total  \n",
    "\n",
    "This dataset contains a large set of news items and their respective social feedback on Facebook, Google + and LinkedIn.\n",
    "\n",
    "\n",
    "### Format\n",
    "One CSV File with News Data Records and 12 CSV Files with Social Feedback.\n",
    "The Social Feedback File contains the feedback from one of the social platforms {Facebook, Google+, LinkedIn} on one of the topics {Economy, Microsoft, Palestine, Obama}.\n",
    "\n",
    "#### News Data Variables\n",
    "Each record contains 11 attributes\n",
    "\n",
    "1. IDLink (numeric): Unique identifier of news items \n",
    "2. Title (string): Title of the news item according to the official media sources \n",
    "3. Headline (string): Headline of the news item according to the official media sources \n",
    "4. Source (string): Original news outlet that published the news item \n",
    "5. Topic (string): Query topic used to obtain the items in the official media sources \n",
    "6. PublishDate (timestamp): Date and time of the news items' publication \n",
    "7. SentimentTitle (numeric): Sentiment score of the text in the news items' title \n",
    "8. SentimentHeadline (numeric): Sentiment score of the text in the news items' headline \n",
    "9. Facebook (numeric): Final value of the news items' popularity according to the social media source Facebook \n",
    "10. GooglePlus (numeric): Final value of the news items' popularity according to the social media source Google+ \n",
    "11. LinkedIn (numeric): Final value of the news items' popularity according to the social media source LinkedIn \n",
    "\n",
    "#### Social Feedback Variables\n",
    "Each record contains 145 attributes\n",
    "\n",
    "1. IDLink (numeric): Unique identifier of news items \n",
    "2. TS1 (numeric): Level of popularity in time slice 1 (0-20 minutes upon publication) \n",
    "3. TS2 (numeric): Level of popularity in time slice 2 (20-40 minutes upon publication) \n",
    "4. TS... (numeric): Level of popularity in time slice ... \n",
    "5. TS144 (numeric): Final level of popularity after 2 days upon publication\n",
    "\n",
    "\n",
    "### Task\n",
    "4 subtasks:\n",
    "+ (20pt) In social feedback data, calculate the average popularity of each news by hour, and by day, respectively\n",
    "+ (20pt) In news data, calculate the sum and average sentiment score of each topic, respectively\n",
    "+ (30pt) In news data, count the words in two fields: ‘Title’ and ‘Headline’ respectively, and list the most frequent words according to the term frequency in descending order, in total, per day, and per topic, respectively\n",
    "+ (30pt) From the previous subtask, for the top-100 frequent words per topic in titles and headlines, calculate their co-occurrence matrices (100x100), respectively. Each entry in the matrix will contain the co-occurrence frequency in all news titles and headlines, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Entity:       org.apache.spark.sql.SparkSession@a512c6\n",
      "Spark version:      2.3.0\n",
      "Spark master:       local[*]\n",
      "Running 'locally'?: true\n"
     ]
    }
   ],
   "source": [
    "// Pre-Configured Spark Context in sc\n",
    "\n",
    "println(\"Spark Entity:       \" + spark)\n",
    "println(\"Spark version:      \" + spark.version)\n",
    "println(\"Spark master:       \" + spark.sparkContext.master)\n",
    "println(\"Running 'locally'?: \" + spark.sparkContext.isLocal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/social/Facebook_Economy.csv\n",
      "./data/social/GooglePlus_Economy.csv\n",
      "./data/social/LinkedIn_Economy.csv\n",
      "./data/social/Facebook_Microsoft.csv\n",
      "./data/social/GooglePlus_Microsoft.csv\n",
      "./data/social/LinkedIn_Microsoft.csv\n",
      "./data/social/Facebook_Obama.csv\n",
      "./data/social/GooglePlus_Obama.csv\n",
      "./data/social/LinkedIn_Obama.csv\n",
      "./data/social/Facebook_Palestine.csv\n",
      "./data/social/GooglePlus_Palestine.csv\n",
      "./data/social/LinkedIn_Palestine.csv\n"
     ]
    }
   ],
   "source": [
    "val folder = \"./data/social/\"\n",
    "val topics = Seq(\"Economy\", \"Microsoft\", \"Obama\", \"Palestine\")\n",
    "val platforms = Seq(\"Facebook\", \"GooglePlus\", \"LinkedIn\")\n",
    "\n",
    "var topic = \"\"\n",
    "var platform = \"\"\n",
    "\n",
    "for(topic <- topics; platform <- platforms){\n",
    "    println(folder+platform+\"_\"+topic+\".csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(Global Active Power -> 1.0572939031266613, Global Reactive Power -> 0.11272195204783488, Global Intensity -> 4.444395175407247, Voltage -> 3.239985888491343)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val std = flattenData.\n",
    "    map{case (k,v) => (k, scala.math.pow(v-average(k),2))}.\n",
    "    reduceByKey((i,j) => i+j).\n",
    "    map{case (k,v) => (k, math.sqrt(v/count(k)))}.collectAsMap()\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(./data/Facebook_Economy.csv, ./data/Facebook_Microsoft.csv, ./data/Facebook_Obama.csv, ./data/Facebook_Palestine.csv, ./data/GooglePlus_Economy.csv, ./data/GooglePlus_Microsoft.csv, ./data/GooglePlus_Obama.csv, ./data/GooglePlus_Palestine.csv, ./data/LinkedIn_Economy.csv, ./data/LinkedIn_Microsoft.csv, ./data/LinkedIn_Obama.csv, ./data/LinkedIn_Palestine.csv)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date;Time;Global_active_power;Global_reactive_power;Voltage;Global_intensity;Sub_metering_1;Sub_metering_2;Sub_metering_3\n",
      "16/12/2006;17:24:00;4.216;0.418;234.840;18.400;0.000;1.000;17.000\n",
      "16/12/2006;17:25:00;5.360;0.436;233.630;23.000;0.000;1.000;16.000\n",
      "16/12/2006;17:26:00;5.374;0.498;233.290;23.000;0.000;2.000;17.000\n",
      "16/12/2006;17:27:00;5.388;0.502;233.740;23.000;0.000;1.000;17.000\n"
     ]
    }
   ],
   "source": [
    "// Remove Header\n",
    "val header = data.first\n",
    "val rows = data.filter(l => l != header)\n",
    "data.take(5).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Global Active Power,4.216)\n",
      "(Global Reactive Power,0.418)\n",
      "(Voltage,234.84)\n",
      "(Global Intensity,18.4)\n",
      "(Global Active Power,5.36)\n",
      "(Global Reactive Power,0.436)\n",
      "(Voltage,233.63)\n",
      "(Global Intensity,23.0)\n",
      "(Global Active Power,5.374)\n",
      "(Global Reactive Power,0.498)\n"
     ]
    }
   ],
   "source": [
    "val flattenData = rows.\n",
    "    flatMap{ dataString =>\n",
    "        dataString.split(\";\").\n",
    "            zipWithIndex.\n",
    "            filter{\n",
    "                case (value,index) => index >= 2 && index <= 5 && value !=\"?\"\n",
    "            }.map{\n",
    "                case (value,index) => \n",
    "                    index match{\n",
    "                        case 2 => (\"Global Active Power\",value.toDouble)\n",
    "                        case 3 => (\"Global Reactive Power\",value.toDouble)\n",
    "                        case 4 => (\"Voltage\",value.toDouble)\n",
    "                        case 5 => (\"Global Intensity\",value.toDouble)\n",
    "                    }\n",
    "                }\n",
    "    }\n",
    "flattenData.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(Global Active Power -> 0.076, Global Reactive Power -> 0.0, Global Intensity -> 0.2, Voltage -> 223.2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val min = flattenData.reduceByKey{(i, j) => if (i<j) i else j}.collectAsMap()\n",
    "min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "103820004 Michael Fu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
